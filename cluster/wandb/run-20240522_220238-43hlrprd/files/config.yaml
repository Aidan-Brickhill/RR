wandb_version: 1

policy_type:
  desc: null
  value: MlpPolicy
total_timesteps:
  desc: null
  value: 2000000
env_name:
  desc: null
  value: HandoverEnv
_wandb:
  desc: null
  value:
    code_path: code/environment/trainwandb.py
    python_version: 3.10.14
    cli_version: 0.17.0
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1716408158
    t:
      1:
      - 1
      - 55
      2:
      - 1
      - 55
      3:
      - 1
      - 2
      - 3
      - 16
      - 22
      - 23
      - 35
      4: 3.10.14
      5: 0.17.0
      8:
      - 5
      13: linux-x86_64
algo:
  desc: null
  value: PPO
policy_class:
  desc: null
  value: <class 'stable_baselines3.common.policies.ActorCriticPolicy'>
device:
  desc: null
  value: cuda
verbose:
  desc: null
  value: 1
policy_kwargs:
  desc: null
  value: '{}'
num_timesteps:
  desc: null
  value: 0
_total_timesteps:
  desc: null
  value: 2000000
_num_timesteps_at_start:
  desc: null
  value: 0
seed:
  desc: null
  value: None
action_noise:
  desc: null
  value: None
start_time:
  desc: null
  value: 1716408170723829658
learning_rate:
  desc: null
  value: 0.0003
tensorboard_log:
  desc: null
  value: runs/43hlrprd
_last_obs:
  desc: null
  value: "[[ 1.34193864e-04 -9.49627258e-04 -1.30300680e-04  2.87665703e-04\n  -1.69920831e-04\
    \ -2.08852713e-04  2.95660353e-04  3.75627165e-04\n   3.45356226e-04 -5.39930056e-01\
    \ -9.72849965e-05  1.87583285e+00\n   5.09037700e-04 -7.41952007e-04 -7.72781331e-04\
    \ -5.25832859e-05\n   5.06932626e-05  1.09276213e-04 -4.17046376e-04 -4.69531759e-04\n\
    \  -3.60461048e-04 -1.03837541e-04  8.43001112e-04 -6.37661163e-04\n   4.76946607e-04\
    \  8.14439984e-04  4.21739717e-04  3.97629130e-04\n   3.76618809e-05 -4.91110459e-04\
    \  5.39930056e-01  9.72849965e-05\n   1.87583285e+00  7.94141390e-04 -2.09156084e-04\
    \  6.12455187e-04\n  -7.73821159e-04 -8.59915752e-04 -9.28353149e-04 -6.27974958e-04\n\
    \   4.45835044e-04  9.80575478e-04 -7.50013719e-01  3.99998949e-01\n   7.74997679e-01\
    \ -4.31056060e-07  3.41303918e-05  7.41636674e-06\n   1.00003968e+00  1.50755211e-06\
    \  2.38509112e-06 -1.78008087e-06\n   1.08715275e-06  1.64448311e-05  3.46628334e-05]\n\
    \ [ 7.84999327e-04  3.48822238e-04  8.73955069e-04 -4.03326780e-04\n  -9.67056678e-04\
    \  7.79736916e-04 -7.21698261e-04 -7.97679791e-04\n   8.10489662e-04 -5.39930056e-01\
    \ -9.72849965e-05  1.87583285e+00\n  -3.93571303e-04 -5.24389793e-04  3.56209362e-04\
    \ -2.42879256e-04\n  -2.93382824e-04 -5.20420505e-04  9.31875910e-04 -6.36360527e-04\n\
    \  -5.79538703e-04  6.19090275e-04  8.12692364e-05  1.33681505e-04\n  -7.62578141e-05\
    \ -7.61879743e-04  4.22295844e-04  7.25921125e-04\n  -8.11218931e-04  4.44318236e-04\
    \  5.39930056e-01  9.72849965e-05\n   1.87583285e+00  3.59951364e-04 -6.03272494e-04\
    \  6.66744401e-04\n  -5.52451424e-04  7.77572490e-04  4.44493433e-04 -2.96328076e-04\n\
    \   6.63846168e-05 -6.99027299e-04 -7.50019127e-01  3.99999923e-01\n   7.74999173e-01\
    \ -6.68772930e-07  2.96120831e-05 -8.75020657e-06\n   9.99994705e-01  1.63874989e-06\
    \ -1.95595520e-06  2.11961709e-07\n   1.89148486e-05  1.97653008e-05  9.58242684e-06]\n\
    \ [ 5.33028846e-04 -4.00884415e-04 -5.40192392e-04  8.08111085e-04\n   9.29498286e-04\
    \  3.09295436e-04 -8.40756410e-04  6.15166728e-04\n   1.15461409e-04 -5.39930056e-01\
    \ -9.72849965e-05  1.87583285e+00\n  -4.76345705e-04  7.61096336e-05 -5.39410382e-04\
    \ -3.57361502e-04\n  -3.82964403e-04  5.51384655e-05  7.07184064e-04  8.60473178e-06\n\
    \  -7.49155055e-04 -8.68720311e-04  3.93677633e-04 -4.47122656e-04\n  -4.10091666e-04\
    \  4.19113748e-04 -4.22715156e-04 -7.08401974e-04\n   7.20223802e-04  3.81708706e-04\
    \  5.39930056e-01  9.72849965e-05\n   1.87583285e+00  5.18495958e-04 -7.24971915e-04\
    \ -7.74098701e-04\n  -4.20597216e-04 -4.62224404e-05 -6.13081198e-04  1.04395657e-04\n\
    \  -2.23774630e-04 -2.48787976e-04 -7.49999225e-01  4.00001044e-01\n   7.74998816e-01\
    \  1.17124268e-06 -2.19236794e-05 -3.64592955e-05\n   9.99963586e-01 -8.95348626e-07\
    \  7.01372298e-07  1.45207913e-06\n   1.43587196e-05 -3.28168433e-06  3.35343204e-05]\n\
    \ [ 2.20479994e-04  3.03206265e-04 -9.23015154e-05  7.95945415e-04\n  -1.72223818e-05\
    \ -2.33594601e-04  6.07506685e-04 -5.19398970e-04\n  -2.23353973e-04 -5.39930056e-01\
    \ -9.72849965e-05  1.87583285e+00\n  -8.38605129e-04  6.57825799e-04  2.31918836e-04\
    \ -4.10239646e-04\n   6.31838786e-04  7.75169310e-04 -2.35006119e-05 -8.29082297e-04\n\
    \   9.82642186e-04 -9.51631012e-04  1.07369117e-04  5.13444154e-04\n  -7.36932500e-04\
    \  7.65377863e-04  6.31500691e-04  9.27543317e-04\n  -2.16915842e-04  5.80028286e-04\
    \  5.39930056e-01  9.72849965e-05\n   1.87583285e+00 -7.63897470e-04  8.37407538e-04\
    \  1.83880723e-06\n   5.37179120e-04  6.66685367e-04  3.61227767e-04  9.51122323e-04\n\
    \   6.83585835e-04 -8.71803942e-04 -7.50042885e-01  4.00002089e-01\n   7.74998498e-01\
    \  4.05193729e-07 -3.29845777e-05  1.69752220e-05\n   1.00000409e+00  8.13388085e-07\
    \  5.47495933e-07 -1.09494882e-07\n   9.11656776e-06 -3.23982229e-05  6.44096857e-06]]"
_last_episode_starts:
  desc: null
  value: '[ True  True  True  True]'
_last_original_obs:
  desc: null
  value: None
_episode_num:
  desc: null
  value: 0
use_sde:
  desc: null
  value: 'False'
sde_sample_freq:
  desc: null
  value: -1
_current_progress_remaining:
  desc: null
  value: 1.0
_stats_window_size:
  desc: null
  value: 100
ep_info_buffer:
  desc: null
  value: deque([], maxlen=100)
ep_success_buffer:
  desc: null
  value: deque([], maxlen=100)
_n_updates:
  desc: null
  value: 0
_custom_logger:
  desc: null
  value: 'False'
env:
  desc: null
  value: <stable_baselines3.common.vec_env.vec_video_recorder.VecVideoRecorder object
    at 0x7f817d18b3a0>
_vec_normalize_env:
  desc: null
  value: None
observation_space:
  desc: null
  value: Box(-inf, inf, (55,), float64)
action_space:
  desc: null
  value: Box(-1.0, 1.0, (18,), float64)
n_envs:
  desc: null
  value: 4
n_steps:
  desc: null
  value: 2048
gamma:
  desc: null
  value: 0.99
gae_lambda:
  desc: null
  value: 0.95
ent_coef:
  desc: null
  value: 0.0
vf_coef:
  desc: null
  value: 0.5
max_grad_norm:
  desc: null
  value: 0.5
rollout_buffer_class:
  desc: null
  value: <class 'stable_baselines3.common.buffers.RolloutBuffer'>
rollout_buffer_kwargs:
  desc: null
  value: '{}'
batch_size:
  desc: null
  value: 64
n_epochs:
  desc: null
  value: 10
clip_range:
  desc: null
  value: <function get_schedule_fn.<locals>.<lambda> at 0x7f8141561ab0>
clip_range_vf:
  desc: null
  value: None
normalize_advantage:
  desc: null
  value: 'True'
target_kl:
  desc: null
  value: None
lr_schedule:
  desc: null
  value: <function get_schedule_fn.<locals>.<lambda> at 0x7f816d33c040>
rollout_buffer:
  desc: null
  value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x7f817d20f940>
policy:
  desc: null
  value: "ActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten):\
    \ Flatten(start_dim=1, end_dim=-1)\n  )\n  (pi_features_extractor): FlattenExtractor(\n\
    \    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (vf_features_extractor):\
    \ FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor):\
    \ MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=55,\
    \ out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64,\
    \ out_features=64, bias=True)\n      (3): Tanh()\n    )\n    (value_net): Sequential(\n\
    \      (0): Linear(in_features=55, out_features=64, bias=True)\n      (1): Tanh()\n\
    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
    \    )\n  )\n  (action_net): Linear(in_features=64, out_features=18, bias=True)\n\
    \  (value_net): Linear(in_features=64, out_features=1, bias=True)\n)"
_logger:
  desc: null
  value: <stable_baselines3.common.logger.Logger object at 0x7f8141565b70>
