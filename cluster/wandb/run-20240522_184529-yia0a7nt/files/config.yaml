wandb_version: 1

policy_type:
  desc: null
  value: MlpPolicy
total_timesteps:
  desc: null
  value: 1000000
env_name:
  desc: null
  value: HandoverEnv
_wandb:
  desc: null
  value:
    code_path: code/environment/trainwandb.py
    python_version: 3.10.14
    cli_version: 0.17.0
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1716396329
    t:
      1:
      - 1
      - 55
      2:
      - 1
      - 55
      3:
      - 1
      - 2
      - 3
      - 16
      - 22
      - 23
      - 35
      4: 3.10.14
      5: 0.17.0
      8:
      - 5
      13: linux-x86_64
algo:
  desc: null
  value: PPO
policy_class:
  desc: null
  value: <class 'stable_baselines3.common.policies.ActorCriticPolicy'>
device:
  desc: null
  value: cuda
verbose:
  desc: null
  value: 1
policy_kwargs:
  desc: null
  value: '{}'
num_timesteps:
  desc: null
  value: 0
_total_timesteps:
  desc: null
  value: 1000000
_num_timesteps_at_start:
  desc: null
  value: 0
seed:
  desc: null
  value: None
action_noise:
  desc: null
  value: None
start_time:
  desc: null
  value: 1716396341181496284
learning_rate:
  desc: null
  value: 0.0003
tensorboard_log:
  desc: null
  value: runs/yia0a7nt
_last_obs:
  desc: null
  value: "[[ 8.50236657e-04  7.80285805e-05 -6.26513641e-04  4.66623386e-04\n   7.80625567e-04\
    \  8.62570503e-04  2.23369330e-04 -1.27395515e-04\n   8.51469811e-04 -5.39930056e-01\
    \ -9.72849965e-05  1.87583285e+00\n  -8.37467164e-04  9.43986747e-04 -8.19578434e-04\
    \  1.24210134e-04\n   3.82972263e-04 -3.62983659e-04  6.48780926e-04 -7.09787682e-05\n\
    \  -6.13045512e-04  3.76604934e-04 -5.20835675e-04 -2.91341029e-04\n   6.91409578e-05\
    \  7.60141482e-04  1.74464020e-05 -1.90687954e-04\n  -4.19561515e-04  4.24461032e-04\
    \  5.39930056e-01  9.72849965e-05\n   1.87583285e+00  2.39556358e-04  5.99407254e-04\
    \ -5.84822498e-04\n  -7.68195622e-04  6.21343696e-05  4.54392681e-04 -1.01892390e-04\n\
    \   5.42163292e-04 -9.21395254e-04 -7.50031061e-01  3.99997703e-01\n   7.75001375e-01\
    \  1.93690107e-07 -4.18220410e-05  4.40725331e-05\n   9.99980990e-01 -1.60299032e-06\
    \  1.35042142e-06  8.75120976e-07\n   2.06145323e-05  2.68875913e-05 -2.86314027e-05]\n\
    \ [-3.13647859e-04  2.68484610e-04 -9.77623491e-04 -6.92924190e-04\n  -4.08543928e-04\
    \  3.09251317e-04  9.10462821e-04  6.88289213e-04\n   8.29114384e-04 -5.39930056e-01\
    \ -9.72849965e-05  1.87583285e+00\n   7.37273764e-04  7.21330800e-04  1.98856870e-04\
    \  8.12134060e-04\n   3.95422626e-05  1.98303073e-05  3.75145388e-04 -6.52196234e-04\n\
    \   3.66137265e-04  4.39007902e-04  8.96400485e-04 -3.36184434e-04\n  -3.68118394e-05\
    \ -5.85609428e-04  4.28809763e-04  6.07208182e-04\n   5.48536832e-04  4.46393282e-04\
    \  5.39930056e-01  9.72849965e-05\n   1.87583285e+00 -1.37576837e-04  1.26586826e-04\
    \  4.77917408e-04\n   1.67327154e-04 -1.09349735e-04 -5.23850990e-04  3.48968579e-04\n\
    \   2.58980297e-05 -7.60165041e-04 -7.50005056e-01  4.00002249e-01\n   7.75000141e-01\
    \ -5.05550087e-07  2.32759221e-05  4.91479071e-06\n   1.00004454e+00 -1.19245632e-06\
    \ -6.69508107e-07 -5.84184658e-09\n   3.45905200e-06 -2.13482065e-05 -1.73708493e-05]\n\
    \ [-9.00440380e-05  7.52081226e-04  6.22970362e-04  9.82533523e-05\n   1.12881188e-04\
    \ -4.19043609e-05  3.11659744e-04 -9.59133777e-04\n   9.79158270e-04 -5.39930056e-01\
    \ -9.72849965e-05  1.87583285e+00\n  -1.52998949e-04 -5.59582255e-06 -5.25312164e-04\
    \ -8.62674615e-04\n  -5.40719730e-04 -9.88540082e-04  5.17613206e-04  1.16018593e-04\n\
    \  -8.85642629e-04 -7.18746898e-04  2.04745544e-04  4.15336433e-04\n   6.22021301e-04\
    \  6.37247232e-04 -4.88114244e-04  1.81090648e-05\n  -5.25870620e-05 -2.03432876e-04\
    \  5.39930056e-01  9.72849965e-05\n   1.87583285e+00 -4.28905938e-04  3.95356392e-04\
    \  6.39589004e-04\n   4.37863356e-04 -8.79325592e-04  2.04656675e-04  5.15742819e-04\n\
    \   5.56392372e-04  3.72313446e-04 -7.49968636e-01  3.99999041e-01\n   7.74999332e-01\
    \ -1.68726852e-07  2.24603662e-05 -1.05978720e-05\n   9.99995005e-01  1.68372701e-06\
    \ -2.95546693e-07 -1.10148820e-06\n   9.74936566e-06  1.46613072e-05  4.22905893e-05]\n\
    \ [ 5.80004118e-04  3.16242894e-04 -9.10116340e-04 -7.29101952e-04\n  -4.25469662e-04\
    \ -2.14139627e-04 -6.48531963e-05 -2.24198833e-04\n  -7.07963767e-04 -5.39930056e-01\
    \ -9.72849965e-05  1.87583285e+00\n  -8.73065826e-04 -3.66349895e-04 -3.10707226e-04\
    \ -7.41975573e-04\n   8.75010604e-04  5.68396998e-05 -5.47882786e-04 -1.68037267e-04\n\
    \   4.37860798e-04 -4.66361848e-04 -1.79802696e-04 -6.30631777e-04\n  -7.67732046e-04\
    \ -4.28543692e-04 -3.25655694e-04 -1.54184962e-04\n  -8.96332177e-06  2.54816037e-05\
    \  5.39930056e-01  9.72849965e-05\n   1.87583285e+00 -2.01219974e-05  6.36098771e-04\
    \  5.14701131e-04\n   8.39701266e-05  4.42796419e-04 -3.64287279e-04  8.61607767e-04\n\
    \   1.31373575e-04  8.33312493e-04 -7.50020743e-01  3.99998039e-01\n   7.74998785e-01\
    \ -4.46981567e-07  4.42721722e-06 -3.22577558e-05\n   9.99993805e-01 -9.52722118e-07\
    \ -1.73241287e-06 -1.82563823e-06\n   2.26302900e-05  5.81348323e-06  4.01178209e-05]]"
_last_episode_starts:
  desc: null
  value: '[ True  True  True  True]'
_last_original_obs:
  desc: null
  value: None
_episode_num:
  desc: null
  value: 0
use_sde:
  desc: null
  value: 'False'
sde_sample_freq:
  desc: null
  value: -1
_current_progress_remaining:
  desc: null
  value: 1.0
_stats_window_size:
  desc: null
  value: 100
ep_info_buffer:
  desc: null
  value: deque([], maxlen=100)
ep_success_buffer:
  desc: null
  value: deque([], maxlen=100)
_n_updates:
  desc: null
  value: 0
_custom_logger:
  desc: null
  value: 'False'
env:
  desc: null
  value: <stable_baselines3.common.vec_env.vec_video_recorder.VecVideoRecorder object
    at 0x7fd8c8b47130>
_vec_normalize_env:
  desc: null
  value: None
observation_space:
  desc: null
  value: Box(-inf, inf, (55,), float64)
action_space:
  desc: null
  value: Box(-1.0, 1.0, (18,), float64)
n_envs:
  desc: null
  value: 4
n_steps:
  desc: null
  value: 2048
gamma:
  desc: null
  value: 0.99
gae_lambda:
  desc: null
  value: 0.95
ent_coef:
  desc: null
  value: 0.0
vf_coef:
  desc: null
  value: 0.5
max_grad_norm:
  desc: null
  value: 0.5
rollout_buffer_class:
  desc: null
  value: <class 'stable_baselines3.common.buffers.RolloutBuffer'>
rollout_buffer_kwargs:
  desc: null
  value: '{}'
batch_size:
  desc: null
  value: 64
n_epochs:
  desc: null
  value: 10
clip_range:
  desc: null
  value: <function get_schedule_fn.<locals>.<lambda> at 0x7fd87ce5dbd0>
clip_range_vf:
  desc: null
  value: None
normalize_advantage:
  desc: null
  value: 'True'
target_kl:
  desc: null
  value: None
lr_schedule:
  desc: null
  value: <function get_schedule_fn.<locals>.<lambda> at 0x7fd8c81e81f0>
rollout_buffer:
  desc: null
  value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x7fd8c8bc6c20>
policy:
  desc: null
  value: "ActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten):\
    \ Flatten(start_dim=1, end_dim=-1)\n  )\n  (pi_features_extractor): FlattenExtractor(\n\
    \    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (vf_features_extractor):\
    \ FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor):\
    \ MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=55,\
    \ out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64,\
    \ out_features=64, bias=True)\n      (3): Tanh()\n    )\n    (value_net): Sequential(\n\
    \      (0): Linear(in_features=55, out_features=64, bias=True)\n      (1): Tanh()\n\
    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
    \    )\n  )\n  (action_net): Linear(in_features=64, out_features=18, bias=True)\n\
    \  (value_net): Linear(in_features=64, out_features=1, bias=True)\n)"
_logger:
  desc: null
  value: <stable_baselines3.common.logger.Logger object at 0x7fd87ce61c00>
