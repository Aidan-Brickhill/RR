diff --git a/cluster/job.batch b/cluster/job.batch
index 1f30995..4c34647 100644
--- a/cluster/job.batch
+++ b/cluster/job.batch
@@ -1,11 +1,11 @@
 #!/bin/bash
 #SBATCH --job-name=rl_train
-#SBATCH --output=/home-mscluster/abrickhill/result.txt
+#SBATCH --output=/home-mscluster/abrickhill/RR/cluster/result.txt
 #SBATCH --ntasks=1
 # increase the time here if you need more than 10 minutes to run your job.
 #SBATCH --time=240:00
 #SBATCH --partition=bigbatch
+export MUJOCO_GL=egl
+python3 ../environment/trainwandb.py
 
-python3 RR/environment/train.py
-
-wait;
\ No newline at end of file
+wait;
diff --git a/environment/__pycache__/franka_env.cpython-310.pyc b/environment/__pycache__/franka_env.cpython-310.pyc
index b1aee38..4d980f6 100644
Binary files a/environment/__pycache__/franka_env.cpython-310.pyc and b/environment/__pycache__/franka_env.cpython-310.pyc differ
diff --git a/environment/__pycache__/handover_env.cpython-310.pyc b/environment/__pycache__/handover_env.cpython-310.pyc
index 6acb722..76d9d90 100644
Binary files a/environment/__pycache__/handover_env.cpython-310.pyc and b/environment/__pycache__/handover_env.cpython-310.pyc differ
diff --git a/environment/__pycache__/utils.cpython-310.pyc b/environment/__pycache__/utils.cpython-310.pyc
index bc0be29..8ab4612 100644
Binary files a/environment/__pycache__/utils.cpython-310.pyc and b/environment/__pycache__/utils.cpython-310.pyc differ
diff --git a/environment/trainwandb.py b/environment/trainwandb.py
index 347b908..945fc2d 100644
--- a/environment/trainwandb.py
+++ b/environment/trainwandb.py
@@ -8,7 +8,7 @@ from wandb.integration.sb3 import WandbCallback
 
 config = {
     "policy_type": "MlpPolicy",
-    "total_timesteps": 100000,
+    "total_timesteps": 1000000,
     "env_name": "HandoverEnv",
 }
 
@@ -21,7 +21,7 @@ run = wandb.init(
 )
 
 def make_env():
-    return Monitor(HandoverEnv(render_mode="rgb_array", tasks_to_complete=["panda_giver_fetch", "panda_reciever_fetch"], max_episode_steps = 80))
+    return Monitor(HandoverEnv(render_mode="rgb_array",tasks_to_complete=["panda_giver_fetch", "panda_reciever_fetch"], max_episode_steps = 80))
 
 env= DummyVecEnv([make_env] * 4)
 env = VecVideoRecorder(
@@ -41,4 +41,4 @@ model.learn(
     ),
 )
 
-run.finish()
\ No newline at end of file
+run.finish()
