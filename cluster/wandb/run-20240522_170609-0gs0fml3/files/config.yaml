wandb_version: 1

policy_type:
  desc: null
  value: MlpPolicy
total_timesteps:
  desc: null
  value: 100000
env_name:
  desc: null
  value: HandoverEnv
_wandb:
  desc: null
  value:
    code_path: code/environment/trainwandb.py
    python_version: 3.10.14
    cli_version: 0.17.0
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1716390369
    t:
      1:
      - 1
      - 55
      2:
      - 1
      - 55
      3:
      - 1
      - 2
      - 3
      - 16
      - 22
      - 23
      - 35
      4: 3.10.14
      5: 0.17.0
      8:
      - 5
      13: linux-x86_64
algo:
  desc: null
  value: PPO
policy_class:
  desc: null
  value: <class 'stable_baselines3.common.policies.ActorCriticPolicy'>
device:
  desc: null
  value: cuda
verbose:
  desc: null
  value: 1
policy_kwargs:
  desc: null
  value: '{}'
num_timesteps:
  desc: null
  value: 0
_total_timesteps:
  desc: null
  value: 100000
_num_timesteps_at_start:
  desc: null
  value: 0
seed:
  desc: null
  value: None
action_noise:
  desc: null
  value: None
start_time:
  desc: null
  value: 1716390380812183389
learning_rate:
  desc: null
  value: 0.0003
tensorboard_log:
  desc: null
  value: runs/0gs0fml3
_last_obs:
  desc: null
  value: "[[ 2.22970167e-04  7.53350612e-04 -3.78060790e-04 -8.04172030e-04\n  -6.07169004e-04\
    \  2.38556178e-04  2.03849555e-04 -4.87544303e-04\n   1.55914593e-04 -5.39930056e-01\
    \ -9.72849965e-05  1.87583285e+00\n   3.61493259e-05  3.52095635e-04 -9.13228446e-04\
    \  7.89230767e-04\n   4.80531718e-04 -2.86944144e-04 -4.75976736e-04 -8.43024909e-04\n\
    \   7.77154153e-04 -1.41333832e-04  1.79843734e-04 -7.28297974e-04\n   1.18192156e-04\
    \  8.75738891e-04 -6.75431206e-04  5.88129214e-04\n   6.92500939e-04  8.93528048e-04\
    \  5.39930056e-01  9.72849965e-05\n   1.87583285e+00  1.57206959e-04 -1.81010087e-04\
    \  5.58202148e-04\n  -4.05563862e-04 -3.40038072e-04 -1.33604601e-04  6.39864416e-04\n\
    \   5.45361663e-04  1.26355318e-04 -7.50041605e-01  4.00000606e-01\n   7.74998527e-01\
    \ -1.97232410e-06  2.69884988e-06  2.46541803e-05\n   1.00000141e+00  4.97930245e-07\
    \ -7.56717154e-07 -2.49221069e-06\n   4.55581149e-05 -3.12317977e-05 -3.17107883e-05]\n\
    \ [-6.26249070e-05  4.34651643e-04  2.75741047e-04 -3.10905837e-04\n   5.00068187e-04\
    \ -9.44742211e-04  6.97449060e-05 -8.61352123e-04\n   2.89695609e-04 -5.39930056e-01\
    \ -9.72849965e-05  1.87583285e+00\n   1.85930717e-04 -3.58662334e-04  3.26164642e-04\
    \ -9.96046606e-04\n   1.59723038e-04 -4.65804594e-04 -7.07084031e-04  9.45692796e-05\n\
    \  -7.31284879e-04  7.53486217e-04 -1.33903704e-04 -1.40672853e-04\n   8.00100974e-04\
    \ -6.50049941e-04  1.76568803e-04  1.77621435e-04\n   1.36076643e-04  9.72210848e-04\
    \  5.39930056e-01  9.72849965e-05\n   1.87583285e+00  7.83262970e-04 -1.14958395e-04\
    \ -1.96724962e-04\n  -9.39897442e-04 -4.54767133e-04 -9.08167384e-04 -1.67016346e-04\n\
    \   8.52997959e-04  2.33880135e-04 -7.49979271e-01  3.99998766e-01\n   7.75001611e-01\
    \  2.12363768e-06 -4.61587609e-05 -1.24715963e-05\n   9.99968312e-01 -7.34456557e-07\
    \ -2.01288695e-06  1.24645926e-06\n   2.44444198e-05 -5.31042228e-06 -1.90779542e-05]\n\
    \ [ 8.55754909e-04  8.22585590e-04 -5.21119974e-04 -8.96775409e-04\n  -3.59408038e-04\
    \ -3.16406970e-04  6.67674302e-04 -2.99072961e-04\n   2.28548496e-04 -5.39930056e-01\
    \ -9.72849965e-05  1.87583285e+00\n   5.46103978e-04  9.35416978e-04  1.06104897e-05\
    \  9.18351558e-04\n  -7.65679894e-05 -1.00504838e-04  3.32370513e-04 -4.75018754e-04\n\
    \  -4.17847288e-04  2.68424159e-04  6.45472099e-04  7.37920933e-04\n  -3.71335226e-05\
    \ -3.82745514e-04 -2.89005641e-04 -9.15667739e-04\n   6.74844291e-04  1.02805769e-04\
    \  5.39930056e-01  9.72849965e-05\n   1.87583285e+00  3.34112779e-04  9.61087982e-04\
    \ -4.80271160e-04\n  -7.44794261e-04  7.02476387e-04 -4.70963733e-04  4.84977564e-04\n\
    \   7.77171314e-04 -2.97378300e-04 -7.50028618e-01  4.00001477e-01\n   7.74999263e-01\
    \  1.66342213e-06  4.14869624e-05  8.16481737e-08\n   9.99951712e-01  1.56557200e-06\
    \  6.60920691e-08 -2.06536213e-06\n   4.87838337e-05 -8.61216282e-06 -2.26377452e-05]\n\
    \ [-9.41782782e-04  5.50969380e-04 -6.18895120e-04 -4.55842838e-04\n   6.02052960e-04\
    \ -6.15801074e-04  2.68165421e-04 -4.72944460e-04\n   8.20132983e-04 -5.39930056e-01\
    \ -9.72849965e-05  1.87583285e+00\n   6.22074706e-04 -8.94091111e-04  6.16139709e-04\
    \  4.07909779e-04\n   5.49878627e-04 -2.80539766e-04  1.08495357e-04 -6.02901571e-04\n\
    \  -1.88412023e-04  1.11464379e-04 -6.61552364e-04  5.98135886e-04\n   4.61836630e-04\
    \ -1.14054287e-04  8.08565601e-04 -9.15314910e-04\n   8.28468804e-04  7.90636983e-04\
    \  5.39930056e-01  9.72849965e-05\n   1.87583285e+00  5.67844703e-04 -8.71786544e-04\
    \ -1.20088121e-04\n  -6.68570256e-04 -4.04422956e-04  2.34662591e-04  1.94632971e-04\n\
    \  -2.33059080e-04 -8.12345444e-04 -7.49951754e-01  3.99998032e-01\n   7.74998896e-01\
    \ -1.04225099e-06  2.77037607e-05  4.44213307e-05\n   1.00002153e+00  6.88814685e-07\
    \ -1.51063503e-06  1.95150374e-06\n   3.57772390e-05 -2.43662410e-05  4.50356544e-05]]"
_last_episode_starts:
  desc: null
  value: '[ True  True  True  True]'
_last_original_obs:
  desc: null
  value: None
_episode_num:
  desc: null
  value: 0
use_sde:
  desc: null
  value: 'False'
sde_sample_freq:
  desc: null
  value: -1
_current_progress_remaining:
  desc: null
  value: 1.0
_stats_window_size:
  desc: null
  value: 100
ep_info_buffer:
  desc: null
  value: deque([], maxlen=100)
ep_success_buffer:
  desc: null
  value: deque([], maxlen=100)
_n_updates:
  desc: null
  value: 0
_custom_logger:
  desc: null
  value: 'False'
env:
  desc: null
  value: <stable_baselines3.common.vec_env.vec_video_recorder.VecVideoRecorder object
    at 0x7fb13e1ef190>
_vec_normalize_env:
  desc: null
  value: None
observation_space:
  desc: null
  value: Box(-inf, inf, (55,), float64)
action_space:
  desc: null
  value: Box(-1.0, 1.0, (18,), float64)
n_envs:
  desc: null
  value: 4
n_steps:
  desc: null
  value: 2048
gamma:
  desc: null
  value: 0.99
gae_lambda:
  desc: null
  value: 0.95
ent_coef:
  desc: null
  value: 0.0
vf_coef:
  desc: null
  value: 0.5
max_grad_norm:
  desc: null
  value: 0.5
rollout_buffer_class:
  desc: null
  value: <class 'stable_baselines3.common.buffers.RolloutBuffer'>
rollout_buffer_kwargs:
  desc: null
  value: '{}'
batch_size:
  desc: null
  value: 64
n_epochs:
  desc: null
  value: 10
clip_range:
  desc: null
  value: <function get_schedule_fn.<locals>.<lambda> at 0x7fb0ee551bd0>
clip_range_vf:
  desc: null
  value: None
normalize_advantage:
  desc: null
  value: 'True'
target_kl:
  desc: null
  value: None
lr_schedule:
  desc: null
  value: <function get_schedule_fn.<locals>.<lambda> at 0x7fb13c40c1f0>
rollout_buffer:
  desc: null
  value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x7fb13e26f130>
policy:
  desc: null
  value: "ActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten):\
    \ Flatten(start_dim=1, end_dim=-1)\n  )\n  (pi_features_extractor): FlattenExtractor(\n\
    \    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (vf_features_extractor):\
    \ FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor):\
    \ MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=55,\
    \ out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64,\
    \ out_features=64, bias=True)\n      (3): Tanh()\n    )\n    (value_net): Sequential(\n\
    \      (0): Linear(in_features=55, out_features=64, bias=True)\n      (1): Tanh()\n\
    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
    \    )\n  )\n  (action_net): Linear(in_features=64, out_features=18, bias=True)\n\
    \  (value_net): Linear(in_features=64, out_features=1, bias=True)\n)"
_logger:
  desc: null
  value: <stable_baselines3.common.logger.Logger object at 0x7fb0ee555cc0>
